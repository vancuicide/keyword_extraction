{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 textRank 的关键词抽取探索\n",
    "本文使用一个简易版本的textRank，以此来了解其机理，并使用nips数据集，进行充分的数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Algorithms for Non-negative Matrix Factorizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Characterizing Neural Gain Control using Spike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Competition Adds Complexity It is known that d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Regularized Boost for Semi-Supervised Learning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                          abstract1\n",
       "0  1861  2000  Algorithms for Non-negative Matrix Factorizati...\n",
       "1  1975  2001  Characterizing Neural Gain Control using Spike...\n",
       "2  3163  2007  Competition Adds Complexity It is known that d...\n",
       "3  3164  2007  Efficient Principled Learning of Thin Junction...\n",
       "4  3167  2007  Regularized Boost for Semi-Supervised Learning..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('data/papers2.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textRank 相关内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 英文预处理相关模块\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "class TextRank(object):\n",
    "    \n",
    "    def __init__(self, sentence, window, alpha, iternum):\n",
    "        \"\"\"\n",
    "        sentence: 原始文本\n",
    "        window: 创建相邻节点所使用的窗口数\n",
    "        alpha: textRank中使用到的参数\n",
    "        iternum: 迭代次数\n",
    "        \"\"\"\n",
    "        self.sentence = sentence\n",
    "        self.window = window\n",
    "        self.alpha = alpha\n",
    "        self.edge_dict = {}  # 记录节点的边连接字典\n",
    "        self.iternum = iternum\n",
    "        \n",
    "    # 获取英文预处理的停用词表\n",
    "    def getStopWords(self):\n",
    "        # Creating a list of stop words and adding custom stopwords\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        # Creating a list of custom stopwords\n",
    "        news_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\"]\n",
    "        self.stop_words = stop_words.union(news_words)\n",
    "        \n",
    "    # 进行英文文本预处理\n",
    "    def dealSentence(self):\n",
    "        # 对self.sentence进行处理\n",
    "        \n",
    "        # 去除标点\n",
    "        text = re.sub('[^a-zA-Z]', ' ', self.sentence)\n",
    "        \n",
    "        # 转化成小写\n",
    "        text = text.lower()\n",
    "        \n",
    "        # 去除符号\n",
    "        text = re.sub(\"</?.*?>\",\" <> \",text)\n",
    "        \n",
    "        # 去除特殊字符和数字\n",
    "        text = re.sub(\"(\\d|\\W)+\",\" \",text)\n",
    "        \n",
    "        # 将列表转换成string\n",
    "        text = text.split()\n",
    "        \n",
    "        # 词干处理\n",
    "        ps = PorterStemmer()\n",
    "        \n",
    "        # 词性\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in self.stop_words]\n",
    "        \n",
    "        self.dealedSen = \" \".join(text)\n",
    "        print(self.dealedSen)\n",
    "        \n",
    "        self.dealedSentence = text\n",
    "        \n",
    "    \n",
    "    # 根据窗口，构建每个节点的相邻节点，返回边的集合\n",
    "    def createNodes(self):\n",
    "        tmp_list = []\n",
    "        word_list_len = len(self.dealedSentence)\n",
    "        for index, word in enumerate(self.dealedSentence):\n",
    "            if word not in self.edge_dict.keys():\n",
    "                tmp_list.append(word)\n",
    "                tmp_set = set()\n",
    "                left = index - self.window + 1  # 窗口左边界\n",
    "                right = index + self.window  # 窗口右边界\n",
    "                # 越界处理\n",
    "                if left < 0:\n",
    "                    left = 0\n",
    "                if right >= word_list_len:\n",
    "                    right = word_list_len\n",
    "                # 取滑动窗口内的不同单词，即建立邻接过程\n",
    "                for i in range(left, right):\n",
    "                    if i == index:\n",
    "                        continue\n",
    "                    tmp_set.add(self.dealedSentence[i])\n",
    "                self.edge_dict[word] = tmp_set\n",
    "    \n",
    "    # 根据边的关系，构建矩阵\n",
    "    def createMatrix(self):\n",
    "        self.matrix = np.zeros([len(set(self.dealedSentence)), len(set(self.dealedSentence))])\n",
    "        self.word_index = {}  # 记录词的index\n",
    "        self.index_dict = {}  # 记录节点index对应的词\n",
    "        \n",
    "        for i, v in enumerate(set(self.dealedSentence)):\n",
    "            self.word_index[v] = i\n",
    "            self.index_dict[i] = v\n",
    "        \n",
    "        for key in self.edge_dict.keys():\n",
    "            for w in self.edge_dict[key]:\n",
    "                self.matrix[self.word_index[key]][self.word_index[w]] = 1\n",
    "                self.matrix[self.word_index[w]][self.word_index[key]] = 1\n",
    "        \n",
    "        # 归一化\n",
    "        for j in range(self.matrix.shape[1]):\n",
    "            summ = 0\n",
    "            for i in range(self.matrix.shape[0]):\n",
    "                summ += self.matrix[i][j]\n",
    "            for i in range(self.matrix.shape[0]):\n",
    "                self.matrix[i][j] /= summ\n",
    "        \n",
    "    # 根据textRank公式计算权重\n",
    "    def calPR(self):\n",
    "        self.PR = np.ones([len(set(self.dealedSentence)), 1])\n",
    "        for i in range(self.iternum):\n",
    "            self.PR = (1 - self.alpha) + self.alpha * np.dot(self.matrix, self.PR)\n",
    "                \n",
    "        \n",
    "    # 输出词和相应的权重\n",
    "    def printResult(self):\n",
    "        word_pr = {}\n",
    "        for i in range(len(self.PR)):\n",
    "            word_pr[self.index_dict[i]] = self.PR[i][0]\n",
    "        res = sorted(word_pr.items(), key=lambda x: x[1], reverse=True)\n",
    "        self.res = res\n",
    "        print(self.res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm non negative matrix factorization non negative matrix factorization nmf useful decomposition multivariate data different multi plicative algorithm nmf analyzed differ slightly multiplicative factor used update rule algorithm minimize conventional least square error minimizes generalized kullback leibler divergence monotonic convergence algorithm proven auxiliary func tion analogous used proving convergence expectation maximization algorithm algorithm interpreted diag onally rescaled gradient descent rescaling factor optimally chosen ensure convergence\n",
      "[('algorithm', 3.3388344271912227), ('convergence', 1.833289867906681), ('factor', 1.6538696136510604), ('nmf', 1.4701989678811866), ('used', 1.4411182860038187), ('factorization', 1.0799689216685375), ('minimizes', 0.9623411657148838), ('error', 0.960089597880959), ('generalized', 0.960024338714584), ('kullback', 0.9516558744814465), ('square', 0.951012145228346), ('onally', 0.9489005556679782), ('rescaled', 0.9433463856538848), ('gradient', 0.9422071387330071), ('least', 0.9388086933114052), ('leibler', 0.937792602932518), ('multivariate', 0.9307557123231659), ('data', 0.9296698942353153), ('different', 0.923815500735214), ('diag', 0.9214553634030687), ('descent', 0.9208316982142275), ('decomposition', 0.9160863238525182), ('rescaling', 0.9149549545015899), ('divergence', 0.9123401254918799), ('optimally', 0.9098143774111876), ('conventional', 0.9082294618143802), ('useful', 0.9045728097565569), ('func', 0.9019258467110886), ('multi', 0.8983772594905858), ('tion', 0.8938724957803592), ('minimize', 0.8927097047770443), ('chosen', 0.892260658028497), ('analogous', 0.8918479487177219), ('differ', 0.889002722233086), ('slightly', 0.8866930200185313), ('matrix', 0.8835809618795221), ('auxiliary', 0.8833064918715383), ('monotonic', 0.8832389692298211), ('plicative', 0.8826818432931163), ('multiplicative', 0.878051926407929), ('non', 0.87402843484776), ('negative', 0.87402843484776), ('analyzed', 0.8728012269736025), ('proving', 0.8717546645141366), ('proven', 0.8694476363884448), ('expectation', 0.8663529298941655), ('rule', 0.8624582374270766), ('update', 0.8509306779922751), ('interpreted', 0.7143923541621585), ('ensure', 0.7060849881110084), ('maximization', 0.6741857620421466)]\n",
      "characterizing neural gain control spike triggered covariance spike triggered averaging technique effective linear characterization neural response neuron exhibit important nonlinear behavior gain control captured analysis describe spike triggered covariance method retrieving suppressive component gain control signal neuron demonstrate method simulation retinal ganglion cell data analysis physiological data reveals significant suppressive ax explains neural nonlinearities method applicable sensory area modality\n",
      "[('method', 1.9734044789047087), ('neural', 1.9281418765856535), ('gain', 1.8672663619790089), ('control', 1.6516169741709534), ('suppressive', 1.5423951828442712), ('analysis', 1.3576135098145747), ('triggered', 1.3418524682361825), ('spike', 1.3169797379980235), ('data', 1.2395066834031936), ('neuron', 1.21870358575738), ('sensory', 1.0024575688522874), ('applicable', 0.9449586669713387), ('effective', 0.8823323166068983), ('ganglion', 0.8794562458174734), ('retinal', 0.8729759163808668), ('simulation', 0.8705798854539939), ('exhibit', 0.8698261988490021), ('linear', 0.8695698062605012), ('characterization', 0.8680367530495026), ('important', 0.865300537480359), ('technique', 0.8645850326999316), ('cell', 0.8628416836648458), ('reveals', 0.8609415032290948), ('nonlinearities', 0.8606011248932458), ('response', 0.855837611437175), ('nonlinear', 0.8538102002591247), ('significant', 0.8502051354831636), ('demonstrate', 0.8491702130821004), ('averaging', 0.8440781331989978), ('explains', 0.8384280844477905), ('ax', 0.8366061069223122), ('behavior', 0.830014720098446), ('retrieving', 0.8259097536703516), ('signal', 0.8178020332577143), ('area', 0.8164211076829857), ('covariance', 0.8161033998331464), ('describe', 0.8079773014830691), ('component', 0.8040889991609593), ('captured', 0.8012519339428706), ('physiological', 0.673399918633881), ('modality', 0.5943415472246236), ('characterizing', 0.4726097002779963)]\n",
      "competition add complexity known determinining whether dec pomdp namely cooperative partially observable stochastic game posg cooperative strategy positive expected reward complete nexp known cooperation affected complexity competitive posgs complexity determining whether team positive expected reward strategy complete class nexp oracle np\n",
      "[('complexity', 1.9508059825109685), ('known', 1.6664447925490888), ('cooperative', 1.6637484640734304), ('nexp', 1.5371399190123949), ('whether', 1.2781598315991305), ('complete', 1.0805311767062684), ('strategy', 1.0781565061991296), ('expected', 1.0761618359101663), ('positive', 1.070249848104813), ('class', 0.9212197195397385), ('stochastic', 0.9182638357479316), ('determining', 0.9132376230707977), ('affected', 0.9092841699187473), ('observable', 0.9067497896458411), ('partially', 0.9057146879910989), ('game', 0.9053227249105653), ('namely', 0.8994165566452714), ('dec', 0.8990559121536591), ('posg', 0.8975720245015846), ('cooperation', 0.8911781370047267), ('team', 0.8900256239949678), ('pomdp', 0.8900213167374514), ('reward', 0.8852329907741172), ('determinining', 0.883424570588017), ('oracle', 0.7679650905681734), ('add', 0.7428013995504786), ('posgs', 0.7369120514994467), ('competitive', 0.736257421269724), ('np', 0.5542428134458208), ('competition', 0.5447031837764493)]\n",
      "efficient principled learning thin junction tree present first truly polynomial algorithm learning structure bounded treewidth junction tree attractive subclass probabilistic graphical model permit compact representation probability distribution efficient exact inference constant treewidth algorithm polynomial time sample complexity provides strong theoretical guarantee term kl divergence true distribution present lazy extension approach lead significant speed ups practice demonstrate viability method empirically several real world datasets key theoretical insight method bounding conditional mutual information arbitrarily set random variable polynomial number mutual information computation fixed size subset variable underlying distribution approximated bounded treewidth junction tree\n",
      "[('distribution', 1.8071375344946352), ('polynomial', 1.7303895821994155), ('learning', 1.5209745943017334), ('theoretical', 1.5111014628348198), ('method', 1.5084002471370757), ('information', 1.4274243778851066), ('variable', 1.4094119598566412), ('present', 1.3971178131723545), ('tree', 1.3734220470471747), ('treewidth', 1.3578503634019712), ('junction', 1.341287293243023), ('mutual', 1.2428693135280793), ('efficient', 1.2185821787954194), ('algorithm', 1.1859547977940412), ('bounded', 0.9896452285933289), ('speed', 0.9640672740024124), ('ups', 0.9620471169728215), ('significant', 0.9604418611784045), ('practice', 0.9573935656323277), ('lead', 0.9510222750513281), ('real', 0.9435078192858269), ('model', 0.942724008874482), ('world', 0.9422482297944863), ('permit', 0.9395218658681393), ('demonstrate', 0.9394954967060155), ('graphical', 0.9367894891574512), ('approach', 0.9367073865776938), ('viability', 0.9338892447061747), ('several', 0.9315234793888434), ('datasets', 0.9303242318938905), ('compact', 0.9301705223753676), ('empirically', 0.9300585026207887), ('probabilistic', 0.9239840467142514), ('key', 0.9228714331701983), ('guarantee', 0.9160468147820325), ('kl', 0.914678636120799), ('strong', 0.9140754457494605), ('term', 0.9126855551479797), ('extension', 0.9083000667183272), ('provides', 0.9081968472049479), ('complexity', 0.9079189442897436), ('representation', 0.9057129954427667), ('insight', 0.9009830265682898), ('subclass', 0.8963088510487793), ('divergence', 0.8948964937198646), ('bounding', 0.8857367903605021), ('probability', 0.8834318233457535), ('fixed', 0.8828858269642322), ('sample', 0.8825042230868717), ('lazy', 0.882388204476382), ('size', 0.8810819323752254), ('subset', 0.8778750697409001), ('true', 0.8748588357421186), ('computation', 0.8742464046383518), ('conditional', 0.870785210882683), ('attractive', 0.8664555178098823), ('arbitrarily', 0.8625031182622552), ('time', 0.8619008688516314), ('set', 0.858436914625079), ('underlying', 0.8559484237248491), ('exact', 0.8529847251019607), ('random', 0.8502683205915716), ('inference', 0.8482075946785537), ('constant', 0.8443954608158497), ('approximated', 0.8356846592241131), ('number', 0.8339718193817302), ('thin', 0.8283187249362771), ('truly', 0.8265004056643873), ('first', 0.8254797162793318), ('structure', 0.8127353323679155), ('principled', 0.6602537550228691)]\n",
      "regularized boost semi supervised learning semi supervised inductive learning concern learn decision rule data set containing labeled unlabeled data several boosting algorithm extended semi supervised learning various strategy knowledge however none take local smoothness constraint among data account ensemble learning paper introduce local smoothness regularizer semi supervised boosting algorithm based universal optimization framework margin cost functionals regularizer applicable existing semi supervised boosting algorithm improve generalization speed training comparative result synthetic benchmark real world task demonstrate effectiveness local smoothness regularizer discus relevant issue relate regularizer previous work\n",
      "[('regularizer', 2.6880846667569496), ('data', 2.2884705100696636), ('learning', 2.070910449266125), ('semi', 1.9142544999252826), ('local', 1.7399626920277624), ('algorithm', 1.5894229391264973), ('smoothness', 1.5437482997344838), ('supervised', 1.5315587721232635), ('boosting', 1.2042040675448002), ('synthetic', 0.9710180547200705), ('result', 0.9695442181026226), ('benchmark', 0.9683162102379537), ('comparative', 0.9641892338117324), ('real', 0.9615647130009641), ('training', 0.9531551746543501), ('world', 0.9487728270608304), ('speed', 0.9377612998722854), ('task', 0.931020969162153), ('framework', 0.9170398972223962), ('optimization', 0.9145793952945941), ('margin', 0.9134694570440374), ('generalization', 0.9080590112926542), ('demonstrate', 0.8980290584734248), ('universal', 0.8937661397567239), ('however', 0.8903802474915831), ('knowledge', 0.8891359420573381), ('cost', 0.8877845242453327), ('relate', 0.8849266118986863), ('improve', 0.8817085796402533), ('none', 0.8737903555378137), ('based', 0.8737451897161088), ('functionals', 0.8733936281507937), ('strategy', 0.8679767237485522), ('effectiveness', 0.8670261975219712), ('issue', 0.8644203746372972), ('relevant', 0.8644203746372972), ('set', 0.8593841357245228), ('labeled', 0.8586760956901915), ('containing', 0.8586760956901915), ('rule', 0.858102591025523), ('decision', 0.8558756337853749), ('learn', 0.8541642143124797), ('unlabeled', 0.8540625978884563), ('take', 0.8532393197931577), ('concern', 0.8466773797072072), ('various', 0.8461394593742309), ('discus', 0.844607056549312), ('applicable', 0.8349271371535562), ('several', 0.8330600600322685), ('among', 0.8240580114951486), ('account', 0.8217746593744463), ('paper', 0.8216501022643363), ('ensemble', 0.8213526546638915), ('existing', 0.8160669091585484), ('constraint', 0.8155653885553978), ('inductive', 0.8153835935719097), ('extended', 0.8149115155494495), ('introduce', 0.8129786117329647), ('previous', 0.7212099253982227), ('boost', 0.6916254239790204), ('work', 0.517547952677835), ('regularized', 0.5086721692877048)]\n",
      "simplified rule theoretical analysis information bottleneck optimization pca spiking neuron suitable assumption primarily linearization simple perspicuous online learning rule information bottleneck optimization spiking neuron derived rule performs common benchmark task well rather complex rule proposed cite klampfletal b furthermore transparency learning rule make theoretical analysis convergence property feasible variation learning rule sign change provides theoretically founded method performing principal component analysis pca spiking neuron applying rule ensemble neuron different principal component input extracted addition possible preferentially extract principal component incoming signal x related related additional target signal y biological interpretation target signal y called relevance variable could represent proprioceptive feedback input sensory modality top signal\n",
      "[('rule', 3.545511585212499), ('signal', 2.2810511114618213), ('learning', 1.9129278540505679), ('component', 1.8468079031736058), ('principal', 1.7010974910142385), ('analysis', 1.6594136085341642), ('input', 1.582994213160954), ('neuron', 1.553778950596937), ('y', 1.2076733405772857), ('target', 1.1951515696400477), ('spiking', 1.1927312307849989), ('theoretical', 1.1811007173766166), ('related', 1.028476272642862), ('pca', 0.9913835100797144), ('information', 0.9869894326987039), ('could', 0.9224555391694869), ('represent', 0.9219080198010022), ('variable', 0.9168536695317449), ('task', 0.9093542643504585), ('linearization', 0.9093269287529229), ('well', 0.9086136260050629), ('primarily', 0.9069564172826513), ('benchmark', 0.9063269898809687), ('simple', 0.9031869688367169), ('theoretically', 0.9015809033428891), ('proprioceptive', 0.8999383128920172), ('provides', 0.8971731141768233), ('founded', 0.8967966095461453), ('relevance', 0.8963848879845854), ('klampfletal', 0.8948287004471719), ('feedback', 0.893260806882056), ('b', 0.8905865588040659), ('assumption', 0.8848218050130614), ('sensory', 0.8843544754655907), ('rather', 0.8805893015682191), ('perspicuous', 0.8783380029989725), ('common', 0.8779019147832012), ('complex', 0.8736759195182967), ('possible', 0.8731842969310369), ('cite', 0.8728710399998624), ('method', 0.872062523543756), ('furthermore', 0.8717113188818618), ('change', 0.8708190625821651), ('proposed', 0.8699073197126657), ('called', 0.867974703782548), ('addition', 0.8654826638242036), ('suitable', 0.864812143433305), ('performs', 0.8633160295952479), ('modality', 0.8610608938293917), ('preferentially', 0.8576573019355535), ('online', 0.8497879160794152), ('sign', 0.8469121971256162), ('transparency', 0.8457021585725908), ('extracted', 0.8446385360785965), ('feasible', 0.8436642991898368), ('performing', 0.8435204450360386), ('property', 0.8388177249772691), ('extract', 0.835441719013585), ('convergence', 0.831572428125424), ('optimization', 0.8293931753248366), ('variation', 0.8287412896998412), ('interpretation', 0.82790431662561), ('biological', 0.82790431662561), ('derived', 0.8261289194544891), ('bottleneck', 0.8192918463904187), ('ensemble', 0.8186621791594803), ('applying', 0.8166399762368886), ('incoming', 0.816170288101121), ('different', 0.8066926058267486), ('make', 0.7952588575542451), ('top', 0.6824752197037295), ('x', 0.6598516062993205), ('additional', 0.6557285591101724), ('simplified', 0.4759375935983869)]\n",
      "predicting human gaze low level saliency combined face detection natural viewing condition human observer shift gaze allocate processing resource subset visual input many computational model aimed predicting voluntary attentional shift although importance high level stimulus property higher order statistic semantics stand undisputed model based low level feature input alone study recorded eye movement human observer viewed photograph natural scene third stimulus contained least person demonstrate combined model face detection low level saliency clearly outperforms low level model predicting location human fixate reflected finding fact observes even instructed look anything particular fixate face probability within first fixation m remarkably model predictive performance image contain face impaired spurious face detector response suggestive bottom mechanism face detection summary provide novel computational approach combine high level object knowledge case face location low level feature successfully predict allocation attentional resource\n",
      "[('face', 3.311958965511484), ('level', 2.739195136892006), ('model', 2.395775226318186), ('human', 2.2589330469941853), ('stimulus', 1.5201281994104257), ('computational', 1.4988524174489246), ('natural', 1.478190868752701), ('shift', 1.4280111585020512), ('gaze', 1.3945472676626447), ('low', 1.3926059426937014), ('fixate', 1.3804250826727649), ('input', 1.3597168906749144), ('detection', 1.3112333684983573), ('high', 1.294097037766066), ('observer', 1.270095717628577), ('predicting', 1.2575704456091454), ('attentional', 1.1383858979056356), ('feature', 1.132777365334217), ('combined', 1.1182225005116715), ('saliency', 1.0802264166625077), ('resource', 1.0296447692741753), ('location', 0.9453828068939838), ('even', 0.9360457994570156), ('instructed', 0.9320437854239315), ('observes', 0.9310033042290023), ('look', 0.9194801991298657), ('fact', 0.9165117674855091), ('statistic', 0.8989258527478431), ('semantics', 0.8951064140356866), ('anything', 0.8936767462379115), ('order', 0.8925195041325297), ('finding', 0.890708314593555), ('fixation', 0.888866270435216), ('first', 0.8862658977663539), ('suggestive', 0.8746404382883342), ('higher', 0.8688522944045085), ('detector', 0.8685076847240795), ('stand', 0.8678787415347727), ('m', 0.8667509210732142), ('within', 0.8633491897516788), ('contain', 0.8620002461036281), ('remarkably', 0.860651734633299), ('recorded', 0.8595721098039802), ('particular', 0.8593169589040386), ('response', 0.8577429052207843), ('study', 0.8534592702196002), ('performance', 0.8517009945533542), ('image', 0.8514958156168264), ('predictive', 0.8514646574915439), ('bottom', 0.8514158438606209), ('reflected', 0.8493567816522347), ('undisputed', 0.8470590264586737), ('probability', 0.8458143141109679), ('least', 0.8450255644959741), ('contained', 0.8445200806808545), ('subset', 0.8437430672311439), ('person', 0.8424698804149808), ('visual', 0.8415332614993101), ('alone', 0.8396044412593121), ('eye', 0.8342389342903376), ('mechanism', 0.8324062169631465), ('allocation', 0.8320797652393072), ('property', 0.8313248700238661), ('novel', 0.8281895628522261), ('demonstrate', 0.8236544780035359), ('processing', 0.8224431002540084), ('third', 0.8207702468231476), ('predict', 0.8200691942254825), ('provide', 0.8177322973184891), ('summary', 0.8153776522927705), ('scene', 0.81288625264063), ('movement', 0.811860223896539), ('many', 0.80983420872531), ('approach', 0.8089441374394596), ('successfully', 0.807078188956003), ('case', 0.8033339683841662), ('allocate', 0.7997056023605854), ('photograph', 0.7995349374041358), ('object', 0.7914139327561458), ('knowledge', 0.7908017328999687), ('aimed', 0.7848840983827853), ('although', 0.783971158214082), ('combine', 0.7838137947931008), ('voluntary', 0.782490374714927), ('based', 0.7801310079018663), ('viewed', 0.7788843310298499), ('viewing', 0.7785434672795454), ('condition', 0.7744236436283745), ('importance', 0.7709801529446026), ('clearly', 0.757480887304697), ('outperforms', 0.757480887304697), ('spurious', 0.6846288069463317), ('impaired', 0.6835512765254128)]\n",
      "mining internet scale software repository repository source code create challenge opportunity statistical machine learning first develop infrastructure automated crawling parsing database storage open source software infrastructure allows u gather internet scale source code instance experiment gather java project sourceforge apache totaling million line code developer simple statistical analysis data first reveal robust power law behavior package sloc method call distribution develop apply unsupervised author topic probabilistic model automatically discover topic embedded code extract topic word author topic distribution addition serving convenient summary program function developer activity related distribution provide statistical information theoretic basis quantifying analyzing developer similarity competence topic scattering document tangling direct application software engineering finally combining software textual content structural information captured coderank approach able significantly improve software retrieval performance increasing auc metric roughly better previous approach based text alone\n",
      "[('software', 3.1082001326842503), ('topic', 2.6774963329471326), ('developer', 2.256354074506003), ('code', 2.247550846225158), ('statistical', 2.056711472502013), ('distribution', 1.7637623627998305), ('approach', 1.7516167936911833), ('gather', 1.6017527651861716), ('information', 1.5841052032065832), ('first', 1.568756083706155), ('develop', 1.5517244628639206), ('infrastructure', 1.2144585064082345), ('source', 1.2042679876803857), ('internet', 1.0610220755389654), ('scale', 1.050681633417418), ('author', 1.0366220999482536), ('based', 1.021190709994273), ('repository', 0.992223083845962), ('roughly', 0.9595237803625368), ('previous', 0.9581945554033322), ('metric', 0.9558643676863253), ('auc', 0.9487191403913536), ('better', 0.9467456088132796), ('behavior', 0.942113667175232), ('law', 0.9380794530626162), ('increasing', 0.9373143771920078), ('package', 0.936443240124079), ('power', 0.9288483357633235), ('sloc', 0.924222698933426), ('sourceforge', 0.9146650356153513), ('apache', 0.913119594295099), ('performance', 0.9059757824831474), ('parsing', 0.9054060447254212), ('database', 0.9051199285316079), ('totaling', 0.9044910668464443), ('robust', 0.9012039478202655), ('able', 0.8980004791536794), ('project', 0.8965057610554844), ('method', 0.8964935461185096), ('summary', 0.8962114907830766), ('convenient', 0.8948966210994495), ('retrieval', 0.8944495432839165), ('tangling', 0.8921947885736008), ('crawling', 0.8913920100611731), ('storage', 0.8896014373563959), ('engineering', 0.8856008462243928), ('java', 0.8843072748163906), ('combining', 0.8838488212079465), ('reveal', 0.8837715708281146), ('improve', 0.8829517755486831), ('coderank', 0.8815573119437786), ('significantly', 0.879684770502791), ('application', 0.8792439381726599), ('serving', 0.8791128606121079), ('direct', 0.87689051166699), ('captured', 0.8767611668387485), ('million', 0.8754891684596566), ('program', 0.8739546638943637), ('document', 0.8721724714567466), ('structural', 0.870634239436743), ('textual', 0.8692470895494077), ('automated', 0.868738599229276), ('call', 0.8683504827394785), ('open', 0.8671060538881062), ('scattering', 0.8643744366970192), ('function', 0.8636193404320864), ('basis', 0.8583527540505511), ('model', 0.8574702507155664), ('automatically', 0.8574702507155664), ('addition', 0.856116848707861), ('discover', 0.8535896741842547), ('probabilistic', 0.8532128909028233), ('content', 0.8531590922991072), ('quantifying', 0.8513539106994658), ('u', 0.8507117248754076), ('analyzing', 0.8494666638475968), ('line', 0.847272398554337), ('experiment', 0.8435164669308579), ('theoretic', 0.8405515487934154), ('data', 0.8386123608132845), ('allows', 0.8381338932937389), ('extract', 0.8372667122712177), ('opportunity', 0.8363174326391017), ('activity', 0.8359244813441025), ('apply', 0.8342480367540188), ('competence', 0.8323958427438394), ('create', 0.8323519143801007), ('embedded', 0.8310707777535743), ('unsupervised', 0.8309364663382282), ('similarity', 0.8297831402856932), ('instance', 0.8292396303861748), ('related', 0.8282481634735286), ('machine', 0.8267606402731202), ('analysis', 0.8244840631773828), ('challenge', 0.8227214592091999), ('provide', 0.8198191737588123), ('learning', 0.8161653988244459), ('text', 0.8061642022167644), ('simple', 0.8031571666703218), ('finally', 0.6911311863782229), ('word', 0.6667072107063414), ('alone', 0.5954162165018663), ('mining', 0.5089896305225852)]\n",
      "continuous time particle filtering fmri construct biologically motivated stochastic differential model neural hemodynamic activity underlying observed blood oxygen level dependent bold signal functional magnetic resonance imaging fmri model pose difficult parameter estimation problem theoretically due nonlinearity divergence differential system computationally due time space complexity adapt particle filter smoother task discus practical approach used tackle difficulty including use sparse matrix parallelisation result demonstrate tractability approach application effective connectivity study\n",
      "[('approach', 1.812336532409148), ('particle', 1.7007756658888007), ('differential', 1.6497096820873804), ('fmri', 1.486442233727887), ('model', 1.484991976476667), ('due', 1.4773426548936217), ('time', 1.3071519389228445), ('effective', 1.0638668632771513), ('application', 1.0175490289092974), ('matrix', 0.9856333785685327), ('level', 0.9855619559644808), ('sparse', 0.9855566596079973), ('dependent', 0.9847131731131229), ('oxygen', 0.9844655760267249), ('use', 0.9841313598994642), ('parallelisation', 0.9825036989082957), ('bold', 0.9816937691638892), ('blood', 0.981183745058526), ('result', 0.9802006513185145), ('including', 0.9797629019554593), ('signal', 0.9763406899654833), ('observed', 0.9754379542249286), ('difficulty', 0.9743711064537245), ('tractability', 0.9724157410074808), ('functional', 0.9672372123163917), ('demonstrate', 0.9662737759557588), ('underlying', 0.9659874317063414), ('tackle', 0.9607074714762696), ('magnetic', 0.9550179158323999), ('used', 0.954791708803981), ('activity', 0.9527771494433661), ('practical', 0.9460082561194603), ('task', 0.9438139232952548), ('discus', 0.9411473069642385), ('resonance', 0.9327698006447767), ('estimation', 0.9313657992634152), ('hemodynamic', 0.9305420063618445), ('parameter', 0.9301356168115268), ('smoother', 0.9270557048006567), ('filter', 0.9213836652697849), ('problem', 0.9184506835667632), ('difficult', 0.9178879335360755), ('imaging', 0.9119719009905244), ('theoretically', 0.9105412920311182), ('adapt', 0.9087833166998521), ('neural', 0.9058074286168438), ('pose', 0.90352201568799), ('construct', 0.9013046060037628), ('biologically', 0.9012727089106707), ('complexity', 0.9000293613548958), ('space', 0.8989441601949291), ('motivated', 0.8969717577924127), ('filtering', 0.8879110582432264), ('stochastic', 0.8877290571826417), ('nonlinearity', 0.8850055592257872), ('divergence', 0.879257754603129), ('system', 0.8777449950665398), ('computationally', 0.8763739312817189), ('connectivity', 0.8550995962247331), ('study', 0.6183499273767357), ('continuous', 0.5158872725147547)]\n",
      "online hebbian learning rule performs independent component analysis independent component analysis ica powerful method decouple signal algorithm performing ica consider temporal correlation signal higher moment amplitude distribution moreover require preprocessing data whitening remove second order correlation paper interested understanding neural mechanism responsible solving ica present online learning rule exploit delayed correlation input rule performs ica detecting joint variation firing rate pre postsynaptic neuron similar local rate based hebbian learning rule\n",
      "[('ica', 2.5309041552297513), ('correlation', 2.166101385248497), ('signal', 1.5983238999075335), ('rate', 1.502154011036576), ('learning', 1.4310955527960232), ('rule', 1.4029406269023519), ('performs', 1.2206667153471247), ('preprocessing', 0.9683460416126753), ('require', 0.9678107827479435), ('data', 0.9650086398456658), ('moreover', 0.9628634916037181), ('whitening', 0.9553572816270268), ('distribution', 0.9523031575164983), ('remove', 0.9438206697566641), ('amplitude', 0.936779978610968), ('neuron', 0.930615933384864), ('understanding', 0.9244039803534245), ('neural', 0.9243148607000717), ('mechanism', 0.922053304589508), ('postsynaptic', 0.9208181049170724), ('similar', 0.9201184314080987), ('pre', 0.9182712318715195), ('local', 0.9142789771438459), ('second', 0.912741268206297), ('moment', 0.9080900177032446), ('firing', 0.9055862734422966), ('order', 0.9025194915288411), ('interested', 0.90085283343558), ('paper', 0.8970330264674261), ('responsible', 0.8965245202100602), ('variation', 0.8965058143329556), ('solving', 0.8879486603341284), ('based', 0.8874988658798649), ('joint', 0.8825493435198853), ('hebbian', 0.88016131321), ('higher', 0.8792373501693295), ('present', 0.8753820131726963), ('detecting', 0.8664592004829269), ('decouple', 0.8648556632472068), ('powerful', 0.8638190890916727), ('analysis', 0.8629057572289394), ('independent', 0.8581561568998923), ('component', 0.8541356361915748), ('method', 0.8526474940022095), ('algorithm', 0.8483981175274417), ('delayed', 0.8450161888554738), ('performing', 0.8438220233280587), ('exploit', 0.8410794663968318), ('input', 0.8402313625172051), ('consider', 0.8387450081095515), ('temporal', 0.8309179849408612), ('online', 0.6968288454101258)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    s = dataset['abstract1'][i]\n",
    "    tr = TextRank(s, 3, 0.85, 700)\n",
    "    tr.getStopWords()\n",
    "    tr.dealSentence()\n",
    "    tr.createNodes()\n",
    "    tr.createMatrix()\n",
    "    tr.calPR()\n",
    "    tr.printResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
